user_input,reference_contexts,reference,persona_name,query_style,query_length,synthesizer_name
How do Agentic AI patterns and workflows integrate with Amazon Web Services to enhance cloud-based solutions?,"['Agentic AI patterns and workﬂows on AWS\nAWS Prescriptive Guidance\nCopyright © 2025 Amazon Web Services, Inc. and/or its aﬃliates. All rights reserved.']","Agentic AI patterns and workflows on AWS are designed to leverage the capabilities of Amazon Web Services, providing a structured approach to implementing AI solutions in the cloud. This integration allows for enhanced operational efficiency and data security, ensuring that cloud-based solutions are both effective and secure.",Cloud Solutions Architect,PERFECT_GRAMMAR,LONG,single_hop_specific_query_synthesizer
How does AWS Prescriptive Guidance contribute to the implementation of Agentic AI patterns and workflows on Amazon Web Services?,"[""AWS Prescriptive Guidance Agentic AI patterns and workﬂows on AWS\nAWS Prescriptive Guidance: Agentic AI patterns and workﬂows on \nAWS\nCopyright © 2025 Amazon Web Services, Inc. and/or its aﬃliates. All rights reserved.\nAmazon's trademarks and trade dress may not be used in connection with any product or service \nthat is not Amazon's, in any manner that is likely to cause confusion among customers, or in any \nmanner that disparages or discredits Amazon. All other trademarks not owned by Amazon are \nthe property of their respective owners, who may or may not be aﬃliated with, connected to, or \nsponsored by Amazon.""]","AWS Prescriptive Guidance provides structured patterns and workflows specifically designed for implementing Agentic AI on Amazon Web Services, ensuring that users can effectively leverage AWS capabilities while adhering to best practices.",Cloud Solutions Architect,PERFECT_GRAMMAR,LONG,single_hop_specific_query_synthesizer
What Agentic AI do?,['AWS Prescriptive Guidance Agentic AI patterns and workﬂows on AWS\nTable of Contents\nIntroduction ..................................................................................................................................... 1\nIntended audience ........................................................................................................................................ 1\nObjectives ....................................................................................................................................................... 1\nAbout this content series ............................................................................................................................ 2\nAgent patterns ................................................................................................................................. 3\nBasic reasoning agents ................................................................................................................................ 4\nArchitecture .............................................................................................................................................. 4\nDescription ................................................................................................................................................ 5\nCapabilities ................................................................................................................................................ 6\nLimitations ................................................................................................................................................ 6\nCommon use cases ................................................................................................................................. 6\nImplementation guidance ..................................................................................................................... 7\nSummary ................................................................................................................................................... 7\nArchitecture .............................................................................................................................................. 7\nDescription ................................................................................................................................................ 8\nCapabilities ................................................................................................................................................ 9\nCommon use cases ................................................................................................................................. 9\nImplementation guidance ..................................................................................................................... 9\nSummary ................................................................................................................................................. 10\nTool-based agents for calling functions ................................................................................................ 10\nArchitecture ............................................................................................................................................ 10\nDescription .............................................................................................................................................. 11\nCapabilities ............................................................................................................................................. 12\nCommon use cases ............................................................................................................................... 12\nImplementation guidance ................................................................................................................... 12\nSummary ................................................................................................................................................. 13\nTool-based agents for servers ................................................................................................................. 13\nArchitecture ............................................................................................................................................ 13\nDescription .............................................................................................................................................. 14\nCapabilities ............................................................................................................................................. 15\nCommon use cases ............................................................................................................................... 15\nImplementation guidance ................................................................................................................... 15\nSummary ................................................................................................................................................. 16\nComputer-use agents ................................................................................................................................ 16\niii'],"Agentic AI patterns and workflows on AWS include various types of agents such as basic reasoning agents, tool-based agents for calling functions, and computer-use agents, each with specific architectures, capabilities, and common use cases.",Cloud Security Analyst,POOR_GRAMMAR,SHORT,single_hop_specific_query_synthesizer
What are the common use cases for Agentic AI as outlined in the AWS Prescriptive Guidance?,['AWS Prescriptive Guidance Agentic AI patterns and workﬂows on AWS\nArchitecture ............................................................................................................................................ 16\nDescription .............................................................................................................................................. 17\nCapabilities ............................................................................................................................................. 18\nCommon use cases ............................................................................................................................... 18\nImplementation guidance ................................................................................................................... 19\nSummary ................................................................................................................................................. 19\nCoding agents ............................................................................................................................................. 19\nArchitecture ............................................................................................................................................ 19\nDescription .............................................................................................................................................. 20\nCapabilities ............................................................................................................................................. 21\nCommon use cases ............................................................................................................................... 21\nImplementation guidance ................................................................................................................... 22\nSummary ................................................................................................................................................. 22\nSpeech and voice agents .......................................................................................................................... 22\nArchitecture ............................................................................................................................................ 22\nDescription .............................................................................................................................................. 23\nCapabilities ............................................................................................................................................. 24\nCommon use cases ............................................................................................................................... 24\nImplementation guidance ................................................................................................................... 24\nSummary ................................................................................................................................................. 25\nWorkﬂow orchestration agents ............................................................................................................... 25\nArchitecture ............................................................................................................................................ 25\nDescription .............................................................................................................................................. 26\nCapabilities ............................................................................................................................................. 27\nCommon use cases ............................................................................................................................... 27\nImplementation guidance ................................................................................................................... 27\nSummary ................................................................................................................................................. 28\nMemory-augmented agents ..................................................................................................................... 28\nArchitecture ............................................................................................................................................ 28\nDescription .............................................................................................................................................. 29\nCapabilities ............................................................................................................................................. 30\nCommon use cases ............................................................................................................................... 30\nImplementing memory-augmented agents .................................................................................... 30\nImplementing memory-injected prompting ................................................................................... 31\nSummary ................................................................................................................................................. 31\nSimulation and test-bed agents ............................................................................................................. 32\niv'],"The common use cases for Agentic AI are detailed in the AWS Prescriptive Guidance, which includes various patterns and workflows that can be implemented across different types of agents, such as coding agents, speech and voice agents, workflow orchestration agents, memory-augmented agents, and simulation and test-bed agents.",Cloud Security Analyst,PERFECT_GRAMMAR,MEDIUM,single_hop_specific_query_synthesizer
"How do user preferences influence the response generation of voice query systems in AWS Agentic AI patterns, particularly in terms of session continuity and contextual awareness?","[""<1-hop>\n\nAWS Prescriptive Guidance Agentic AI patterns and workﬂows on AWS\n• User preferences\n• Past decisions and outcomes\n• Learned concepts, summaries, or experiences\n4. Reasons through the LLM\n• The memory context is embedded into the LLM prompt, allowing the agent to reason based \non both current inputs and prior knowledge.\n5. Generates outputs\n• The agent produces a contextually aware response, plan, or action that is personalized \naccording to the task history and user's inputs.\n6. Updates memory\n• New information, such as updated goals, success and failure signals, and structured responses, \nare stored for future tasks.\nCapabilities\n• Session continuity across conversations or events\n• Goal persistence over time\n• Contextual awareness based on an evolving state\n• Adaptability informed by prior successes and failures\n• Personalization aligned with user preferences and history\nCommon use cases\n• Conversational copilots that remember user preferences\n• Coding agents that track codebase changes\n• Workﬂow agents that adapt according to task history\n• Digital twins that evolve from system knowledge\n• Research agents that avoid redundant retrievals\nImplementing memory-augmented agents\nUse the following tools and AWS services for memory-augmented agents:\nCapabilities 30"", '<2-hop>\n\nAWS Prescriptive Guidance Agentic AI patterns and workﬂows on AWS\nDescription\n1. Receives a voice query\n• The user voices a request to a phone, microphone, or embedded system.\n• A speech-to-text (STT) module converts the audio to text.\n2. Integrates streaming and telephony context\n• The agent uses a streaming interface to manage audio I/O in real time.\n• If it\'s deployed in a contact center or telecom context, telephony integration handles session \nrouting, dual-tone multi-frequency (DTMF) input, and media transport.\nNote: DTMF refers to the tones generated when you press buttons on a telephone keypad. In the \ncontext of streaming and telephony context integration within voice agents, DTMF is used as a \nsignal input mechanism during a phone call, especially in interactive voice response (IVR) systems. \nDTMF inputs enable the agent to:\n• Recognize menu selections (for example, ""Press 1 for billing. Press 2 for support."")\n• Collect numeric inputs (for example, account numbers, PINs, and conﬁrmation numbers)\nDescription 23']","User preferences play a crucial role in the response generation of voice query systems within AWS Agentic AI patterns. When a user voices a request, the system not only processes the voice query through a speech-to-text module but also integrates past decisions and outcomes to personalize the response. This personalization is achieved by embedding the memory context into the LLM prompt, allowing the agent to reason based on both current inputs and prior knowledge. As a result, the agent can maintain session continuity across conversations, ensuring that responses are contextually aware and aligned with the user's history and preferences. This adaptability informed by prior successes and failures enhances the overall user experience, making the interaction more efficient and tailored to individual needs.",,,,multi_hop_abstract_query_synthesizer
How does the feedback control loop integrate with the operations of a research agent in AWS Prescriptive Guidance workflows?,"['<1-hop>\n\nAWS Prescriptive Guidance Agentic AI patterns and workﬂows on AWS\nFeedback control loop\nA feedback control loop is a pattern that monitors its own outputs and behaviors, evaluates them \nagainst deﬁned criteria or a desired state, and then adjusts its actions accordingly. This architecture \nis inspired by control theory and is foundational in domains such as automation, continuous \nintegration and continuous delivery (CI/CD) pipelines, and machine learning operations.\nThe following diagram is an example of a feedback control loop:\nFeedback control loop 74', '<2-hop>\n\nAWS Prescriptive Guidance Agentic AI patterns and workﬂows on AWS\n• Assigns a research agent to ﬁnd competitor data\n• Sends the raw ﬁndings to a summarization agent\n• Passes results to a brief-writer agent\n• Compiles the ﬁnal output for the user\nEach agent operates independently, but the orchestrator coordinates the tasks. This is like a \nLambda function that handles workﬂow tasks.\nThe following diagram an example of a supervisor:\n1. A user submits a task to an Amazon Bedrock supervisor agent.\n2. The supervisor agent parses the request into subtasks for each agent collaborator.\n3. Each subtask is assigned to a collaborator agent with role-speciﬁc prompts or toolchains.\n4. Worker agents call external APIs or tools through an action group.\n5. Each worker agent returns the output in a structured format.\n6. When all workers return their results, the supervisor evaluates, synthesizes, and returns the ﬁnal \nresponse.\nSupervisor 72']","The feedback control loop in AWS Prescriptive Guidance is a pattern that monitors outputs and behaviors, evaluates them against defined criteria, and adjusts actions accordingly. This loop is foundational for automation and continuous integration. In the context of a research agent, it assigns tasks to find competitor data, which is then processed by a summarization agent and compiled by a brief-writer agent. The orchestrator coordinates these tasks, ensuring that the feedback control loop effectively evaluates the performance of each agent and adjusts the workflow as necessary to optimize the final output for the user.",,,,multi_hop_abstract_query_synthesizer
How does AWS Prescriptive Guidance handle a voice query and what tools are used for creating a reasoning agent?,"[""<1-hop>\n\nAWS Prescriptive Guidance Agentic AI patterns and workﬂows on AWS\nImplementation guidance\nYou can use the following tools and services to create a basic reasoning agent:\n• Amazon Bedrock for LLM invocation (Anthropic, AI21, Meta)\n• Amazon API Gateway or AWS Lambda to expose it as a stateless microservice\n• Prompt templates stored in Parameter Store, AWS Secrets Manager, or as code\nSummary\nThe basic reasoning agent is foundational because of its simple structure. It has core capabilities \nthat turn goals into reasoning paths that lead to intelligent outputs. This pattern is often a starting \npoint for advanced patterns, such as tool-based agents and agents that use retrieval-augmented \ngeneration (RAG). It's also a reliable and modular component of large workﬂows.\nAgent RAG\nRetrieval-augmented generation (RAG) is a technique that combines information retrieval with \ntext generation to create accurate and contextual responses. RAG enables agents to retrieve \nrelevant external information before engaging the LLM. It extends an agent's eﬀective memory \nand reasoning accuracy by grounding its decisions in up-to-date, factual, or domain-speciﬁc \ninformation. In contrast to stateless LLMs that rely solely on pretrained weights, RAG has an \nexternal knowledge search layer that dynamically enhances prompts with context.\nArchitecture\nThe logic of the RAG pattern is illustrated in the following diagram:\nImplementation guidance 7"", '<2-hop>\n\nAWS Prescriptive Guidance Agentic AI patterns and workﬂows on AWS\nDescription\n1. Receives a voice query\n• The user voices a request to a phone, microphone, or embedded system.\n• A speech-to-text (STT) module converts the audio to text.\n2. Integrates streaming and telephony context\n• The agent uses a streaming interface to manage audio I/O in real time.\n• If it\'s deployed in a contact center or telecom context, telephony integration handles session \nrouting, dual-tone multi-frequency (DTMF) input, and media transport.\nNote: DTMF refers to the tones generated when you press buttons on a telephone keypad. In the \ncontext of streaming and telephony context integration within voice agents, DTMF is used as a \nsignal input mechanism during a phone call, especially in interactive voice response (IVR) systems. \nDTMF inputs enable the agent to:\n• Recognize menu selections (for example, ""Press 1 for billing. Press 2 for support."")\n• Collect numeric inputs (for example, account numbers, PINs, and conﬁrmation numbers)\nDescription 23', '<3-hop>\n\nAWS Prescriptive Guidance Agentic AI patterns and workﬂows on AWS\nArchitecture ............................................................................................................................................ 32\nDescription .............................................................................................................................................. 33\nCapabilities ............................................................................................................................................. 34\nCommon use cases ............................................................................................................................... 34\nImplementation guidance ................................................................................................................... 35\nSummary ................................................................................................................................................. 35\nObserver and monitoring agents ........................................................................................................... 36\nArchitecture ............................................................................................................................................ 36\nDescription .............................................................................................................................................. 36\nCapabilities ............................................................................................................................................. 37\nCommon use cases ............................................................................................................................... 37\nImplementation guidance ................................................................................................................... 38\nSummary ................................................................................................................................................. 38\nMulti-agent collaboration ......................................................................................................................... 39\nDescription .............................................................................................................................................. 40\nCapabilities ............................................................................................................................................. 41\nCommon use cases ............................................................................................................................... 41\nImplementation guidance ................................................................................................................... 41\nSummary ................................................................................................................................................. 42\nConclusion .............................................................................................................................................. 42\nTakeaways ............................................................................................................................................... 42\nLLM workﬂows ............................................................................................................................... 44\nOverview of LLM-augmented cognition ................................................................................................ 44\nWorkﬂow for prompt chaining ............................................................................................................... 45\nDescription .............................................................................................................................................. 46\nCapabilities ............................................................................................................................................. 46\nCommon use cases ............................................................................................................................... 47\nWorkﬂow for routing ................................................................................................................................ 47\nCapabilities ............................................................................................................................................. 48\nCommon use cases ............................................................................................................................... 48\nWorkﬂow for parallelization .................................................................................................................... 48\nCapabilities ............................................................................................................................................. 50\nCommon use cases ............................................................................................................................... 50\nWorkﬂow for orchestration ...................................................................................................................... 50\nCapabilities ............................................................................................................................................. 51\nCommon use cases ............................................................................................................................... 51\nv']","AWS Prescriptive Guidance handles a voice query by first receiving the user's request through a phone, microphone, or embedded system, where a speech-to-text (STT) module converts the audio to text. For creating a basic reasoning agent, tools such as Amazon Bedrock for LLM invocation, Amazon API Gateway or AWS Lambda to expose it as a stateless microservice, and prompt templates stored in Parameter Store or AWS Secrets Manager are utilized.",,,,multi_hop_abstract_query_synthesizer
How does the voice query process integrate with event-driven execution in AWS workflows?,"['<1-hop>\n\nAWS Prescriptive Guidance Agentic AI patterns and workﬂows on AWS\nDescription\n1. Receives a voice query\n• The user voices a request to a phone, microphone, or embedded system.\n• A speech-to-text (STT) module converts the audio to text.\n2. Integrates streaming and telephony context\n• The agent uses a streaming interface to manage audio I/O in real time.\n• If it\'s deployed in a contact center or telecom context, telephony integration handles session \nrouting, dual-tone multi-frequency (DTMF) input, and media transport.\nNote: DTMF refers to the tones generated when you press buttons on a telephone keypad. In the \ncontext of streaming and telephony context integration within voice agents, DTMF is used as a \nsignal input mechanism during a phone call, especially in interactive voice response (IVR) systems. \nDTMF inputs enable the agent to:\n• Recognize menu selections (for example, ""Press 1 for billing. Press 2 for support."")\n• Collect numeric inputs (for example, account numbers, PINs, and conﬁrmation numbers)\nDescription 23', '<2-hop>\n\nAWS Prescriptive Guidance Agentic AI patterns and workﬂows on AWS\n• The chosen worker agent receives the event or prompt and begins running commands.\n• It can track execution state, retry on failure, and pass intermediate results to the next agent in \nthe sequence.\nCapabilities\n• Agent composition (for example, supervisors, collaborator agents, and tools)\n• Event-driven or scheduled execution\n• Memory and state tracking over time\n• Hierarchical or parallel task orchestration (synchronous compared with asynchronous workﬂows)\n• Dynamic agent selection and chaining\nCommon use cases\n• Multistep automation (for example, data ingestion and reporting)\n• Customer service routing and escalation (for example, agent-as-coordinator)\n• AI agents coordinate with humans and bots within the same loop\n• Automates enterprise processes using LLM-powered logic\n• Hybrid systems combine AI agents and traditional orchestration tools\nImplementation guidance\nYou can build this pattern using the following tools and AWS services:\n• Amazon Bedrock for reasoning and agent selection\n• AWS Step Functions or Amazon EventBridge for workﬂow composition\n• AWS Lambda as execution units or task runners\n• Amazon DynamoDB, Amazon Simple Storage Service (Amazon S3), or Amazon RDS to track \nstates and results\n• AWS AppFabric or Amazon AppFlow for cross-system coordination\n• (Optional) Use Amazon SageMaker run agent to host domain-speciﬁc worker agents\nCapabilities 27']","The voice query process in AWS workflows begins when the user voices a request, which is converted from audio to text by a speech-to-text (STT) module. This process is integrated with event-driven execution as the chosen worker agent receives the event or prompt from the voice query and starts running commands. The agent can track execution state, retry on failure, and pass intermediate results to the next agent in the sequence, allowing for a seamless interaction between voice input and automated responses.",,,,multi_hop_abstract_query_synthesizer
"What role does Amazon EC2 play in the migration strategy to the AWS Cloud, and how does it integrate with other AWS services in the context of implementing Agentic AI patterns and workflows?","['<1-hop>\n\nAWS Prescriptive Guidance Agentic AI patterns and workﬂows on AWS\nmigration engineers, developers, and DevOps professionals working in sprints. Between 20 \nand 50 percent of an enterprise application portfolio consists of repeated patterns that can \nbe optimized by a factory approach. For more information, see the discussion of migration \nfactories and the Cloud Migration Factory guide in this content set.\nmigration metadata\nThe information about the application and server that is needed to complete the migration. \nEach migration pattern requires a diﬀerent set of migration metadata. Examples of migration \nmetadata include the target subnet, security group, and AWS account.\nmigration pattern\nA repeatable migration task that details the migration strategy, the migration destination, and \nthe migration application or service used. Example: Rehost migration to Amazon EC2 with AWS \nApplication Migration Service.\nMigration Portfolio Assessment (MPA)\nAn online tool that provides information for validating the business case for migrating to \nthe AWS Cloud. MPA provides detailed portfolio assessment (server right-sizing, pricing, TCO \ncomparisons, migration cost analysis) as well as migration planning (application data analysis \nand data collection, application grouping, migration prioritization, and wave planning). The\nMPA tool (requires login) is available free of charge to all AWS consultants and APN Partner \nconsultants.\nMigration Readiness Assessment (MRA)\nThe process of gaining insights about an organization’s cloud readiness status, identifying \nstrengths and weaknesses, and building an action plan to close identiﬁed gaps, using the AWS \nCAF. For more information, see the migration readiness guide. MRA is the ﬁrst phase of the AWS \nmigration strategy.\nmigration strategy\nThe approach used to migrate a workload to the AWS Cloud. For more information, see the 7 Rs\nentry in this glossary and see Mobilize your organization to accelerate large-scale migrations.\nML\nSee machine learning.\nM 105', '<2-hop>\n\nAWS Prescriptive Guidance Agentic AI patterns and workﬂows on AWS\nImplementation guidance\n• You can build this pattern using the following AWS services:\n• Amazon Bedrock for LLM-based planning and reasoning\n• Amazon Elastic Compute Cloud (Amazon EC2), AWS Lambda, or Amazon SageMaker notebooks \nto run tool servers with simulated UI environments\n• Amazon Simple Storage Service (Amazon S3) or Amazon DynamoDB for memory persistence\n• Amazon Rekognition (or custom models) for UI image analysis in hybrid scenarios\n• Amazon CloudWatch Logs or AWS X-Ray for observability and audit trails\nSummary\nComputer-use agents act as autonomous digital operators, bridging the gap between human-\ncomputer interactions and AI-driven actions. By incorporating memory, tool orchestration, and \nVLMs, these agents can adaptively interact with systems designed for humans, execute actions, \nupdate ﬁles, navigate menus, and generate responses.\nCoding agents\nCoding agents can reason about programming tasks, generate or modify code, and interact \nwith developer environments, such as IDEs and CLIs. These agents combine natural-language \nunderstanding with structured reasoning to assist, augment, and automate software development, \nranging from function generation to bug ﬁxing and test authoring.\nUnlike autocomplete tools, coding agents actively interpret user goals, query the development \nenvironment for context (for example, it opens ﬁles and traces errors), identify requirements, and \nthen propose and perform actions.\nArchitecture\nA coding-agent pattern is shown in the following diagram:\nImplementation guidance 19']","Amazon EC2 plays a crucial role in the migration strategy to the AWS Cloud by serving as a destination for rehost migrations, as detailed in the migration pattern examples. It is utilized alongside other AWS services such as AWS Lambda and Amazon SageMaker notebooks to run tool servers with simulated UI environments. This integration allows for the implementation of Agentic AI patterns and workflows, where computer-use agents can autonomously interact with systems, execute actions, and generate responses, thereby enhancing the efficiency and effectiveness of cloud-based applications and services.",,,,multi_hop_specific_query_synthesizer
How do AWS Prescriptive Guidance and Agentic AI patterns relate to Amazon's trademarks and their usage restrictions?,"[""<1-hop>\n\nAWS Prescriptive Guidance Agentic AI patterns and workﬂows on AWS\nAWS Prescriptive Guidance: Agentic AI patterns and workﬂows on \nAWS\nCopyright © 2025 Amazon Web Services, Inc. and/or its aﬃliates. All rights reserved.\nAmazon's trademarks and trade dress may not be used in connection with any product or service \nthat is not Amazon's, in any manner that is likely to cause confusion among customers, or in any \nmanner that disparages or discredits Amazon. All other trademarks not owned by Amazon are \nthe property of their respective owners, who may or may not be aﬃliated with, connected to, or \nsponsored by Amazon.""]","AWS Prescriptive Guidance includes Agentic AI patterns and workflows on AWS, which are developed under the copyright of Amazon Web Services, Inc. and its affiliates. Amazon's trademarks and trade dress cannot be used in connection with any product or service that is not Amazon's, in a way that could confuse customers, or in a manner that disparages or discredits Amazon. This highlights the importance of adhering to Amazon's trademark policies while utilizing AWS services.",,,,multi_hop_specific_query_synthesizer
"What are the capabilities of Amazon Lex V2 in the context of AWS Prescriptive Guidance for Agentic AI patterns and workflows, particularly in relation to real-time speech understanding and generation?","['<1-hop>\n\nAWS Prescriptive Guidance Agentic AI patterns and workﬂows on AWS\n• Trigger workﬂows or state transitions in call ﬂows\n• Revert from speech to touch-tone when necessary\n1. Reasons through LLM stream context\n• The query is sent to the agent, which passes it, along with any session metadata (for example, \ncaller ID, prior context), to an LLM.\n• The LLM generates a response, possibly using a chain-of-thought strategy or multiturn \nmemory if the interaction is ongoing.\n2. Returns a voice response\n• The agent converts its response to speech using text-to-speech (TTS).\n• It returns audio to the user through a voice channel.\nCapabilities\n• Real-time speech understanding and generation\n• Multilingual I/O with STT and TTS support\n• Integration with telephony or streaming APIs\n• Session awareness and memory handoﬀ between turns\nCommon use cases\n• Conversational IVR systems\n• Virtual receptionists and appointment schedulers\n• Voice-driven helpdesk agents\n• Wearable voice assistants\n• Voice interfaces for smart homes and accessibility tools\nImplementation guidance\nYou can build this pattern using the following tools and AWS services:\n• Amazon Lex V2 or Amazon Transcribe for STT\n• Amazon Polly for TTS\nCapabilities 24']","Amazon Lex V2 provides several capabilities in the context of AWS Prescriptive Guidance for Agentic AI patterns and workflows. It enables real-time speech understanding and generation, supports multilingual input and output with speech-to-text (STT) and text-to-speech (TTS) functionalities, and integrates seamlessly with telephony or streaming APIs. Additionally, it offers session awareness and memory handoff between turns, making it suitable for various applications such as conversational IVR systems, virtual receptionists, voice-driven helpdesk agents, and more.",,,,multi_hop_specific_query_synthesizer
How do you create an endpoint service in the Amazon Virtul Private Cloud (Amazon VPC) and what role does it play in managing environments such as production and development?,"['<1-hop>\n\nAWS Prescriptive Guidance Agentic AI patterns and workﬂows on AWS\ninformation, see Create an endpoint service in the Amazon Virtual Private Cloud (Amazon VPC) \ndocumentation.\nenterprise resource planning (ERP)\nA system that automates and manages key business processes (such as accounting, MES, and \nproject management) for an enterprise.\nenvelope encryption\nThe process of encrypting an encryption key with another encryption key. For more \ninformation, see Envelope encryption in the AWS Key Management Service (AWS KMS) \ndocumentation.\nenvironment\nAn instance of a running application. The following are common types of environments in cloud \ncomputing:\n• development environment – An instance of a running application that is available only to the \ncore team responsible for maintaining the application. Development environments are used \nto test changes before promoting them to upper environments. This type of environment is \nsometimes referred to as a test environment.\n• lower environments – All development environments for an application, such as those used \nfor initial builds and tests.\n• production environment – An instance of a running application that end users can access. In a \nCI/CD pipeline, the production environment is the last deployment environment.\n• upper environments – All environments that can be accessed by users other than the core \ndevelopment team. This can include a production environment, preproduction environments, \nand environments for user acceptance testing.\nepic\nIn agile methodologies, functional categories that help organize and prioritize your work. Epics \nprovide a high-level description of requirements and implementation tasks. For example, AWS \nCAF security epics include identity and access management, detective controls, infrastructure \nsecurity, data protection, and incident response. For more information about epics in the AWS \nmigration strategy, see the program implementation guide.\nERP\nSee enterprise resource planning.\nE 94']","To create an endpoint service in the Amazon Virtual Private Cloud (Amazon VPC), you would refer to the AWS documentation that provides guidance on setting up such services. The Amazon VPC plays a crucial role in managing different environments, including production and development. A production environment is an instance of a running application that end users can access, while development environments are used for testing changes before they are promoted to upper environments. This structure ensures that applications are secure and efficient within the cloud infrastructure.",,,,multi_hop_specific_query_synthesizer
